{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from datetime import time\n",
    "import re\n",
    "\n",
    "#from scipy.stats import kruskal\n",
    "#from statsmodels.stats.multicomp import pairwise_tukeyhsd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Written by Nathan Hadland\n",
    "#nkhadland@arizona.edu \n",
    "\n",
    "#Modified 1/8/24 by NKH, updated to work with Python 3.13\n",
    "\n",
    "#First version 10/28/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setup\n",
    "### Input path to filenames for the time csv and the data csv here: \n",
    "data_file = 'holuhraun_atp_total.csv'\n",
    "time_array = 'time_array.csv'\n",
    "save_path = \"\"\n",
    "\n",
    "extract_vol1 = 5. #Volume of Tris added during extraction \n",
    "sample_vol1 = 5. #Weight or volume of sample added (e.g., 5g, L of filtrate, etc.). Set to None if you prefer to do your own calculations later. \n",
    "seperate_tris1 = True #T/F whether to have multiple linear regressions for a longer experiement. Currently setup for two, but email Nathan if you'd like the code to be expanded to have 3 or more linear regressions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data and convert to datetime format \n",
    "#Perform the integral for each method using the trapezoid method\n",
    "\n",
    "def integrate_data(RLU_file, time_file):\n",
    "    df = pd.read_csv(RLU_file) \n",
    "    time_df = pd.read_csv(time_file)\n",
    "    time_df = time_df.iloc[[0]] \n",
    "    time_df.iloc[0] = pd.to_datetime(time_df.iloc[0], format='%H:%M').dt.time\n",
    "    integrals = {}\n",
    "\n",
    "    # Loop through each column except the 'Time' column\n",
    "    for column in df.columns:\n",
    "        if column != 'Time':\n",
    "            integral = np.trapezoid(df[column], df['Time'])\n",
    "            integrals[column] = integral\n",
    "\n",
    "    df_total = pd.DataFrame.from_dict(integrals, orient='index', columns=['Integral'])\n",
    "    time_dict = time_df.iloc[0].to_dict()\n",
    "\n",
    "# Add the time column to the df by matching on the index\n",
    "    df_total['Time'] = df_total.index.map(time_dict)\n",
    "    return (df_total,time_df,integrals)\n",
    "    \n",
    "    \n",
    "df1,time_df1,integrals1=integrate_data(data_file,time_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###The main function takes 4 arguments: the input dataframe, a True/False indicator whether to seperate out the Tris values, and the x bounds. The first xbound is the upper bound of the first line and second is the lower bound of the second line.  \n",
    "def time_to_seconds_relative(times,min_time1):\n",
    "    \"\"\"Convert a list of datetime.time objects to seconds relative to the earliest time (e.g., the start of the experiment).\"\"\"\n",
    "    if isinstance(min_time1, time):\n",
    "        min_time_in_seconds = min_time1.hour * 3600 + min_time1.minute * 60 + min_time1.second\n",
    "    else:\n",
    "        min_time_in_seconds = min_time1\n",
    "    times_in_seconds = [t.hour * 3600 + t.minute * 60 + t.second if isinstance(t, time) else t for t in times]\n",
    "    return [t - min_time_in_seconds for t in times_in_seconds]\n",
    "\n",
    "def plot_tris_samples(df,seperate_tris,x_bound1=None, x_bound2=None):\n",
    "    # Filter rows that have \"Tris\" in their index (sample names\n",
    "    datetime_values = df['Time'][df['Time'].apply(lambda x: isinstance(x, (pd.Timestamp, time)))]\n",
    "    min_time = min(datetime_values) ##Extract experiment start time for relative measurements \n",
    "    \n",
    "    tris_df = df[df.index.str.contains('Tris')]\n",
    "\n",
    "    # Extract times and integrals for these samples\n",
    "    times = tris_df['Time'].values\n",
    "    integrals = tris_df['Integral'].values\n",
    "    times_in_seconds = time_to_seconds_relative(times,min_time)\n",
    "    #times_in_seconds = [time_to_seconds(t) if isinstance(t, time) else t for t in times]\n",
    "\n",
    "    if seperate_tris == False:\n",
    "        slope, intercept = np.polyfit(times_in_seconds, integrals, 1)\n",
    "        best_fit_line = slope * np.array(times_in_seconds) + intercept\n",
    "        # Plotting the data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(times_in_seconds, integrals, marker='o', color='k')\n",
    "        plt.plot(times_in_seconds, best_fit_line, color='r', label=f'Best-fit line (slope={slope:.2f})')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Integral')\n",
    "        plt.title('Tris : Time vs Integrals with Best-Fit Line')\n",
    "        plt.show()\n",
    "\n",
    "        predicted_tris_luminescence = []\n",
    "        for idx, row in df.iterrows():\n",
    "            sample_time = row['Time']\n",
    "            if isinstance(sample_time, time):\n",
    "                sample_time_in_seconds = time_to_seconds_relative([sample_time],min_time)[0]\n",
    "            else:\n",
    "                sample_time_in_seconds = sample_time\n",
    "            \n",
    "            # Calculate the predicted Tris luminescence using the curve\n",
    "            predicted_luminescence = slope * sample_time_in_seconds + intercept\n",
    "            predicted_tris_luminescence.append(predicted_luminescence)\n",
    "    \n",
    "    if seperate_tris == True:\n",
    "        if x_bound1 is None or x_bound2 is None:\n",
    "            raise ValueError(\"x_bound1 and x_bound2 must be provided when separate_tris is True\")\n",
    "        # Split indices based on the x bounds\n",
    "        mask1 = np.array(times_in_seconds) <= x_bound1\n",
    "        mask2 = np.array(times_in_seconds) > x_bound1\n",
    "        \n",
    "        # Perform linear regression on each subset\n",
    "        slope1, intercept1 = np.polyfit(np.array(times_in_seconds)[mask1], np.array(integrals)[mask1], 1)\n",
    "        slope2, intercept2 = np.polyfit(np.array(times_in_seconds)[mask2], np.array(integrals)[mask2], 1)\n",
    "\n",
    "        # Plotting the data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(times_in_seconds, integrals, marker='o', color='k')\n",
    "        plt.plot(np.array(times_in_seconds)[mask1], slope1 * np.array(times_in_seconds)[mask1] + intercept1, color='r', label=f'Best-fit line 1 (slope={slope1:.2f})')\n",
    "        plt.plot(np.array(times_in_seconds)[mask2], slope2 * np.array(times_in_seconds)[mask2] + intercept2, color='b', label=f'Best-fit line 2 (slope={slope2:.2f})')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time (seconds since start)')\n",
    "        plt.ylabel('Integral')\n",
    "        plt.title('Tris : Time vs Integrals with Separate Best-Fit Lines')\n",
    "        plt.show()\n",
    "\n",
    "        predicted_tris_luminescence = []\n",
    "        for idx, row in df.iterrows():\n",
    "            sample_time = row['Time']\n",
    "            if isinstance(sample_time, time):\n",
    "                sample_time_in_seconds = time_to_seconds_relative([sample_time],min_time)[0]\n",
    "            else:\n",
    "                sample_time_in_seconds = sample_time\n",
    "            \n",
    "            # Calculate the predicted Tris luminescence based on which segment the time falls into\n",
    "            if sample_time_in_seconds <= x_bound1:\n",
    "                predicted_luminescence = slope1 * sample_time_in_seconds + intercept1\n",
    "                \n",
    "            else:\n",
    "                predicted_luminescence = slope2 * sample_time_in_seconds + intercept2\n",
    "\n",
    "            predicted_tris_luminescence.append(predicted_luminescence)\n",
    "\n",
    "    # Add the predicted Tris luminescence to the DataFrame\n",
    "    df['Predicted_Tris_Luminescence'] = predicted_tris_luminescence\n",
    "    df['Corrected_Luminescence'] = df['Integral'] - df['Predicted_Tris_Luminescence']\n",
    "    for index, row in df.iterrows(): # set negative values to 0\n",
    "        if row['Corrected_Luminescence'] < 0: \n",
    "            df.at[index, 'Corrected_Luminescence'] = 0. \n",
    "    plt.savefig(save_path+\"Tris_vs_Time.png\")\n",
    "    return (df)\n",
    "\n",
    "df1 = plot_tris_samples(df1,seperate_tris1, x_bound1=2500,x_bound2=2501)\n",
    "df2 = plot_tris_samples(df1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the concentration of standards\n",
    "def extract_concentration(index):\n",
    "    if index.startswith('0.'):\n",
    "        # For concentrations less than 1, match '0.X' where X is digits\n",
    "        match = re.match(r'^0\\.\\d+', index)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "    elif index[0].isdigit():\n",
    "        # For concentrations greater than or equal to 1, match digits before any dot\n",
    "        match = re.match(r'^(\\d+)', index)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "    return None  # For non-standard indices like 'Tris'\n",
    "\n",
    "# Apply the function to the index\n",
    "df1['Standard_Concentration'] = df1.index.to_series().apply(extract_concentration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_concentration(df,extract_vol,sample_vol=None):\n",
    "    # Extract the number before the first decimal in the index, if it exists\n",
    "    # For small values like \"0.5\" and \"0.1\", keep them intact\n",
    "    # Group by the standard names and calculate mean values for times and corrected luminescence\n",
    "    #df['Standard_Concentration'] = pd.to_numeric(df['Standard_Concentration'], errors='coerce')\n",
    "    standards_df = df[df['Standard_Concentration'].notna()]\n",
    "    standard_df = standards_df.groupby('Standard_Concentration').mean(numeric_only=True).reset_index()\n",
    "    #standard_df = df.dropna(subset=['Standard_Concentration']).groupby('Standard_Concentration').mean().reset_index()\n",
    "    dropped_rows = df[df['Standard_Concentration'].isna()]\n",
    "    samples = dropped_rows[~dropped_rows.index.str.contains('Tris', na=False)].copy()\n",
    "    \n",
    "    # Extract times and corrected luminescence for the standards\n",
    "    corrected_luminescence = standard_df['Corrected_Luminescence'].values\n",
    "    concentrations = standard_df[\"Standard_Concentration\"].values \n",
    "\n",
    "\n",
    "    # Calculate the best fit line for the standards (standard curve)\n",
    "    standard_slope, standard_intercept = np.polyfit(concentrations, corrected_luminescence, 1)\n",
    "    samples.loc[:, 'Concentration [ng/mL]'] = samples['Corrected_Luminescence'] / standard_slope\n",
    "    if sample_vol == None: \n",
    "        samples.loc[:, \"Original_Sample_Concentration\"] = samples[\"Concentration [ng/mL]\"] * extract_vol \n",
    "    else: \n",
    "        samples.loc[:, \"Original_Sample_Concentration\"] = (\n",
    "        samples[\"Concentration [ng/mL]\"] * extract_vol / sample_vol\n",
    "        )\n",
    "    # Generate the best fit line for the standard curve\n",
    "    best_fit_standard_curve = standard_slope * np.array(concentrations) + standard_intercept\n",
    "\n",
    "    #These lines make a new column if there are triplicate samples and rename a new column without the numbered indices. \n",
    "    samples.index = samples.index.astype(str)\n",
    "    samples['Base_Sample'] = samples.index.str.split('.').str[0]\n",
    "\n",
    "    # Plot the standard curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(concentrations, corrected_luminescence, marker='o', color='g', label='Standards')\n",
    "    plt.plot(concentrations, best_fit_standard_curve, color='r', label=f'Standard curve (slope={standard_slope:.2f})')\n",
    "    plt.xlabel('[ATP] ng/mL')\n",
    "    plt.ylabel('Corrected Luminescence')\n",
    "    plt.title('Standard Curve: Corrected Luminescence vs Time')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path+\"ATP_Standard_Curve.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return (samples)\n",
    "    \n",
    "samples1 = calculate_sample_concentration(df1,extract_vol1,sample_vol=sample_vol1)\n",
    "samples1.to_csv(save_path+\"atp_results.csv\", sep=',', index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
